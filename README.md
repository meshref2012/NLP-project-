# NLP-project
The provided code implements a character-level text generation model using Recurrent Neural Networks (RNN) trained on Wikipedia text related to "Artificial intelligence." The goal is to generate coherent text resembling the style and content of the input text based on a provided seed text.
The purpose of this code is to build and train a character-level language model using RNN (Recurrent Neural Networks). The model takes sequences of characters as input and learns to predict the next character in the sequence. This type of model can be used for tasks like text generation, where the model generates text one character at a time based on the provided input sequences. The RNN layers help capture dependencies in the text data, and the model is optimized using the Adam optimizer with the sparse categorical cross-entropy loss function. After training for 50 epochs, the model should be capable of generating new text based on the patterns learned from the training data.
